{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Importo las clases implementadas en scripts/\n",
    "from scripts.dataset_torchaudio import SpectrogramTensorDataset\n",
    "from scripts.train_regression import SmallCNNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6200ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAR EL DATASET\n",
    "    # EJECUTAR scripts/barridoFMconLabels.py para generar los archivos .wav y sus etiquetas\n",
    "    # Ejecutar scripts/ConversionWavEspec_TorchAudio.py para generar los tensores (scripts/ConversionWavEspec_Librosa.py obsoleto) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de9b28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    filename  carrier  ratio  index\n",
      "0  pru_1.wav      100   0.05    1.5\n",
      "1  pru_2.wav      100   0.05    2.0\n",
      "2  pru_3.wav      100   0.05    2.5\n",
      "3  pru_4.wav      100   0.05    3.0\n",
      "4  pru_5.wav      100   0.05    3.5\n",
      "    filename  carrier  ratio  index tensor_name\n",
      "0  pru_1.wav      100   0.05    1.5    pru_1.pt\n",
      "1  pru_2.wav      100   0.05    2.0    pru_2.pt\n",
      "2  pru_3.wav      100   0.05    2.5    pru_3.pt\n",
      "3  pru_4.wav      100   0.05    3.0    pru_4.pt\n",
      "4  pru_5.wav      100   0.05    3.5    pru_5.pt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer CSV de etiquetas\n",
    "labels_df = pd.read_csv(\"Datasets\\datasetFMwav\\labels.csv\")\n",
    "print(labels_df.head())\n",
    "\n",
    "# Crear nueva columna con el nombre del tensor \n",
    "labels_df[\"tensor_name\"] = labels_df[\"filename\"].str.replace(\".wav\", \".pt\")\n",
    "print(labels_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344fe1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset total: 15051, train: 12040, test: 3011\n"
     ]
    }
   ],
   "source": [
    "# Usaremos la implementación de SpectrogramTensorDataset ya definida en `scripts/dataset_torchaudio.py`\n",
    "# Esta carga los .pt y devuelve (tensor, [carrier, ratio, index])\n",
    "\n",
    "dataset = SpectrogramTensorDataset(\n",
    "    tensors_dir=\"Datasets\\\\datasetFMespec_torchaudio\",\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "# Dividir en train/test (80/20)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Dataset total: {len(dataset)}, train: {len(train_dataset)}, test: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c607a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo (usamos la pequeña CNN implementada en scripts/train_regression.py)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    # IMPORTANTE: en un futuro deberíamos intentar usar GPU, depende de la máquina que nos den para ejecutar esto\n",
    "print('Device:', device)\n",
    "\n",
    "model = SmallCNNRegressor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b87ea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 100777.7298\n",
      "Epoch 2, Loss: 75039.0604\n",
      "Epoch 3, Loss: 67153.3299\n",
      "Epoch 4, Loss: 59819.8289\n",
      "Epoch 5, Loss: 54382.8706\n"
     ]
    }
   ],
   "source": [
    "# Bucle de entrenamiento | De momento aleatorio, deberíamos ver cual es la buena combinación de epochs/batch size/lr\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e845cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE carrier: 162229.875\n",
      "MSE ratio: 3.0819621086120605\n",
      "MSE index: 12.466989517211914\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo en el conjunto de test\n",
    "model.eval()\n",
    "preds, trues = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        preds.append(outputs.cpu())\n",
    "        trues.append(labels.cpu())\n",
    "\n",
    "preds = torch.cat(preds)\n",
    "trues = torch.cat(trues)\n",
    "\n",
    "mse = ((preds - trues)**2).mean(0)  # Se calcula MSE (Mean Squared Error) por cada una de las 3 salidas \n",
    "print(\"MSE carrier:\", mse[0].item())\n",
    "print(\"MSE ratio:\", mse[1].item())\n",
    "print(\"MSE index:\", mse[2].item())\n",
    "\n",
    "# En mi ejecución de prueba me ha dado:   \n",
    "# MSE carrier: 138493.484375 \n",
    "# MSE ratio: 3.073957681655884 \n",
    "# MSE index: 6.215304851531982\n",
    "# \n",
    "# Estos valores indican que el carrier falla mucho (creo que porque va de 100Hz en 100Hz)              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff000bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Esto tengo entendido que es util pero de momento da igual\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sns.heatmap(\u001b[43mcm\u001b[49m, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m\"\u001b[39m\u001b[33md\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mPredicted\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m plt.ylabel(\u001b[33m\"\u001b[39m\u001b[33mTrue\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "# Esto tengo entendido que es util pero de momento da igual\n",
    "#sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "#plt.xlabel(\"Predicted\")\n",
    "#plt.ylabel(\"True\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da88ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda el modelo, no hace falta  \n",
    "torch.save(model.state_dict(), \"cnn_spectrogram.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4774c24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores reales:\n",
      "Carrier: 100.00 Hz\n",
      "Ratio: 0.3000\n",
      "Index: 1.5000\n",
      "Predicción:\n",
      "Carrier: 123.48 Hz\n",
      "Ratio: 0.6098\n",
      "Index: -0.5910\n"
     ]
    }
   ],
   "source": [
    "# Prueba del modelo con un archivo .wav específico\n",
    "import torchaudio\n",
    "from scripts.dataset_torchaudio import waveform_to_spectrogram_tensor\n",
    "from scripts.utils import get_true_labels\n",
    "\n",
    "# Ruta del archivo .wav a predecir\n",
    "wav_path = \"pru_96.wav\"\n",
    "\n",
    "# Cargar audio\n",
    "waveform, sample_rate = torchaudio.load(wav_path)\n",
    "\n",
    "# Convertir a espectrograma (usando la misma lógica que en el dataset)\n",
    "spec_tensor = waveform_to_spectrogram_tensor(waveform, sample_rate)\n",
    "\n",
    "# Asegurar dimensiones correctas y añadir batch\n",
    "spec_tensor = spec_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "# Obtener valores reales\n",
    "true_carrier, true_ratio, true_index = get_true_labels(wav_path)\n",
    "\n",
    "# Mostrar comparación\n",
    "print(\"\\nValores reales:\")\n",
    "print(f\"Carrier: {true_carrier:.2f} Hz\")\n",
    "print(f\"Ratio: {true_ratio:.4f}\")\n",
    "print(f\"Index: {true_index:.4f}\")\n",
    "\n",
    "# Predecir\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(spec_tensor).cpu().numpy()[0]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Predicción:\")\n",
    "print(f\"Carrier: {prediction[0]:.2f} Hz\")\n",
    "print(f\"Ratio: {prediction[1]:.4f}\")\n",
    "print(f\"Index: {prediction[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03bc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
