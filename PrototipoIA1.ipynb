{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "import os\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a5e396fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# DEFINICIÃ“N DE PARÃMETROS\n",
        "\n",
        "DATASET_DIR = \"datasetPrueba\"           # Directorio donde se guardarÃ¡ el dataset generado\n",
        "os.makedirs(DATASET_DIR, exist_ok=True) # Crea el directorio si no existe (exist_ok=True evita error si ya existe)\n",
        "\n",
        "# ParÃ¡metros de audio\n",
        "sample_rate = 44100  \n",
        "duration = 1.0       # DuraciÃ³n de cada muestra\n",
        "\n",
        "# Lista de frecuencias (en Hz)\n",
        "frequencies = [220, 330, 440, 550, 660, 770, 880, 990, 1100, 1320] \n",
        "\n",
        "# Tipos de ondas que se generarÃ¡n\n",
        "wave_types = [\"sine\", \"square\", \"sawtooth\", \"triangle\", \"noise\"]\n",
        "\n",
        "# FunciÃ³n que genera la forma de onda segÃºn el tipo, frecuencia y duraciÃ³n\n",
        "def generate_waveform(wave_type, freq, duration, sample_rate):\n",
        "    # Vector de tiempo desde 0 hasta duraciÃ³n, con pasos segÃºn la frecuencia de muestreo\n",
        "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
        "\n",
        "    # GeneraciÃ³n de diferentes tipos de onda\n",
        "    if wave_type == \"sine\":       \n",
        "        wave = np.sin(2 * np.pi * freq * t)\n",
        "    elif wave_type == \"square\":    \n",
        "        wave = np.sign(np.sin(2 * np.pi * freq * t))\n",
        "    elif wave_type == \"sawtooth\":  \n",
        "        wave = 2 * (t * freq - np.floor(0.5 + t * freq))\n",
        "    elif wave_type == \"triangle\":  \n",
        "        wave = 2 * np.abs(2 * (t * freq - np.floor(0.5 + t * freq))) - 1\n",
        "    elif wave_type == \"noise\":     # Ruido blanco\n",
        "        wave = np.random.uniform(-1, 1, len(t))\n",
        "    else:\n",
        "        # Error si se pasa un tipo de onda no reconocido\n",
        "        raise ValueError(f\"Tipo de onda no reconocido: {wave_type}\")\n",
        "\n",
        "    return wave\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "750fac1f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generando dataset de sonidos...\n",
            "Finalizado con Ã©xito!!! Dataset generado en: c:\\Users\\dvcen\\Desktop\\TFG\\datasetPrueba\n"
          ]
        }
      ],
      "source": [
        "# GENERACION DATASET\n",
        "\n",
        "print(\"Generando dataset de sonidos...\")\n",
        "\n",
        "for wave in wave_types:\n",
        "    # Crea un subdirectorio por tipo de onda\n",
        "    folder = os.path.join(DATASET_DIR, wave)\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    # Genera un archivo de audio para cada frecuencia\n",
        "    for freq in frequencies:\n",
        "        # Genera la onda correspondiente\n",
        "        signal = generate_waveform(wave, freq, duration, sample_rate)\n",
        "\n",
        "        # Normaliza la seÃ±al y convierte a formato int16 (formato WAV estÃ¡ndar)\n",
        "        signal_int16 = np.int16(signal / np.max(np.abs(signal)) * 32767)\n",
        "\n",
        "        # Nombre del archivo WAV\n",
        "        filename = os.path.join(folder, f\"{wave}_{freq}Hz.wav\")\n",
        "\n",
        "        # Guarda la seÃ±al como archivo WAV\n",
        "        write(filename, sample_rate, signal_int16)\n",
        "\n",
        "\n",
        "print(\"Finalizado con Ã©xito!!! Dataset generado en:\", os.path.abspath(DATASET_DIR))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2acd1e71",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… CaracterÃ­sticas extraÃ­das: 50 muestras, 13 features por muestra\n"
          ]
        }
      ],
      "source": [
        "# EXTRACCIÃ“N DE CARACTERÃSTICAS\n",
        "# MFCC (Mel-Frequency Cepstral Coefficients) son caracterÃ­sticas que resumen la forma del sonido y son muy usadas en reconocimiento de audio.\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for wave_type in os.listdir(DATASET_DIR):  # Se busca la carpeta donde se guardÃ³ el dataset\n",
        "    folder = os.path.join(DATASET_DIR, wave_type)\n",
        "    if not os.path.isdir(folder):\n",
        "        continue\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        if file.endswith(\".wav\"):\n",
        "            path = os.path.join(folder, file)\n",
        "            audio, sr = librosa.load(path, sr=44100)  #librosa.load carga el audio y lo convierte en un vector de nÃºmeros (audio) que representa la amplitud de la onda en cada instante de tiempo.\n",
        "            \n",
        "            mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)  # Calcula los 13 MFCC del audio\n",
        "            mfcc_mean = np.mean(mfcc, axis=1)                       # Calcula la media de cada MFCC a lo largo del tiempo\n",
        "            X.append(mfcc_mean)                                     # AÃ±ade las caracterÃ­sticas al dataset\n",
        "            y.append(wave_type)                                     # AÃ±ade la etiqueta correspondiente\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"âœ… CaracterÃ­sticas extraÃ­das: {X.shape[0]} muestras, {X.shape[1]} features por muestra\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d51a4278",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conjunto de entrenamiento: (40, 13)\n",
            "Conjunto de prueba: (10, 13)\n"
          ]
        }
      ],
      "source": [
        "# PREPARACIÃ“N DE DATOS PARA ENTRENAMIENTO\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)  # [\"sine\", \"square\", \"triangle\", \"sawtooth\", \"noise\"] -> [0, 1, 2, 3, 4]\n",
        "\n",
        "# Divide el dataset en entrenamiento y prueba.\n",
        "    # test_size=0.2 -> 20% de los datos van a prueba, 80% a entrenamiento.\n",
        "    # random_state=42 -> garantiza que la divisiÃ³n sea reproducible.\n",
        "    # stratify=y_encoded -> clases niveladas en ambos conjuntos\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "X_train = X_train / np.max(np.abs(X_train))\n",
        "X_test = X_test / np.max(np.abs(X_test))\n",
        "\n",
        "print(f\"Conjunto de entrenamiento: {X_train.shape}\")\n",
        "print(f\"Conjunto de prueba: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc2e0f4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ§  Entrenando modelo...\n",
            "Epoch 1/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.3750 - loss: 1.5834 - val_accuracy: 0.6250 - val_loss: 1.5614\n",
            "Epoch 2/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5312 - loss: 1.5659 - val_accuracy: 0.6250 - val_loss: 1.5458\n",
            "Epoch 3/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5312 - loss: 1.5504 - val_accuracy: 0.6250 - val_loss: 1.5307\n",
            "Epoch 4/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5625 - loss: 1.5358 - val_accuracy: 0.6250 - val_loss: 1.5160\n",
            "Epoch 5/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5938 - loss: 1.5210 - val_accuracy: 0.6250 - val_loss: 1.4997\n",
            "Epoch 6/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6250 - loss: 1.5058 - val_accuracy: 0.6250 - val_loss: 1.4838\n",
            "Epoch 7/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6250 - loss: 1.4912 - val_accuracy: 0.6250 - val_loss: 1.4653\n",
            "Epoch 8/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6250 - loss: 1.4736 - val_accuracy: 0.6250 - val_loss: 1.4467\n",
            "Epoch 9/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6250 - loss: 1.4554 - val_accuracy: 0.6250 - val_loss: 1.4270\n",
            "Epoch 10/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6250 - loss: 1.4369 - val_accuracy: 0.6250 - val_loss: 1.4057\n",
            "Epoch 11/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6250 - loss: 1.4170 - val_accuracy: 0.6250 - val_loss: 1.3841\n",
            "Epoch 12/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5938 - loss: 1.3961 - val_accuracy: 0.6250 - val_loss: 1.3613\n",
            "Epoch 13/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5938 - loss: 1.3738 - val_accuracy: 0.6250 - val_loss: 1.3364\n",
            "Epoch 14/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5938 - loss: 1.3508 - val_accuracy: 0.6250 - val_loss: 1.3094\n",
            "Epoch 15/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5938 - loss: 1.3259 - val_accuracy: 0.6250 - val_loss: 1.2819\n",
            "Epoch 16/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5938 - loss: 1.3003 - val_accuracy: 0.6250 - val_loss: 1.2558\n",
            "Epoch 17/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6250 - loss: 1.2719 - val_accuracy: 0.6250 - val_loss: 1.2265\n",
            "Epoch 18/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5938 - loss: 1.2441 - val_accuracy: 0.6250 - val_loss: 1.1975\n",
            "Epoch 19/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6250 - loss: 1.2155 - val_accuracy: 0.6250 - val_loss: 1.1671\n",
            "Epoch 20/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6250 - loss: 1.1878 - val_accuracy: 0.6250 - val_loss: 1.1360\n",
            "Epoch 21/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6250 - loss: 1.1573 - val_accuracy: 0.6250 - val_loss: 1.1057\n",
            "Epoch 22/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6562 - loss: 1.1274 - val_accuracy: 0.6250 - val_loss: 1.0752\n",
            "Epoch 23/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6562 - loss: 1.0980 - val_accuracy: 0.6250 - val_loss: 1.0448\n",
            "Epoch 24/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6562 - loss: 1.0695 - val_accuracy: 0.6250 - val_loss: 1.0168\n",
            "Epoch 25/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6562 - loss: 1.0403 - val_accuracy: 0.6250 - val_loss: 0.9897\n",
            "Epoch 26/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6562 - loss: 1.0120 - val_accuracy: 0.6250 - val_loss: 0.9637\n",
            "Epoch 27/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6875 - loss: 0.9847 - val_accuracy: 0.6250 - val_loss: 0.9374\n",
            "Epoch 28/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7188 - loss: 0.9593 - val_accuracy: 0.6250 - val_loss: 0.9137\n",
            "Epoch 29/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7188 - loss: 0.9327 - val_accuracy: 0.6250 - val_loss: 0.8901\n",
            "Epoch 30/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7188 - loss: 0.9070 - val_accuracy: 0.6250 - val_loss: 0.8652\n",
            "Epoch 31/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7188 - loss: 0.8837 - val_accuracy: 0.6250 - val_loss: 0.8420\n",
            "Epoch 32/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7188 - loss: 0.8602 - val_accuracy: 0.6250 - val_loss: 0.8224\n",
            "Epoch 33/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7188 - loss: 0.8381 - val_accuracy: 0.6250 - val_loss: 0.8023\n",
            "Epoch 34/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7500 - loss: 0.8172 - val_accuracy: 0.6250 - val_loss: 0.7817\n",
            "Epoch 35/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7500 - loss: 0.7974 - val_accuracy: 0.6250 - val_loss: 0.7648\n",
            "Epoch 36/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7500 - loss: 0.7799 - val_accuracy: 0.6250 - val_loss: 0.7470\n",
            "Epoch 37/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7500 - loss: 0.7610 - val_accuracy: 0.6250 - val_loss: 0.7336\n",
            "Epoch 38/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7500 - loss: 0.7441 - val_accuracy: 0.6250 - val_loss: 0.7193\n",
            "Epoch 39/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7500 - loss: 0.7288 - val_accuracy: 0.6250 - val_loss: 0.7063\n",
            "Epoch 40/40\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7500 - loss: 0.7151 - val_accuracy: 0.6250 - val_loss: 0.6934\n"
          ]
        }
      ],
      "source": [
        "# CONSTRUCCIÃ“N Y ENTRENAMIENTO DEL MODELO\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1],)),                        # Capa de entrada con el nÃºmero de caracterÃ­sticas\n",
        "    layers.Dense(64, activation='relu'),                            # Capa oculta con 64 neuronas y activaciÃ³n ReLU\n",
        "    layers.Dense(32, activation='relu'),                            # Capa oculta con 32 neuronas y activaciÃ³n ReLU\n",
        "    layers.Dense(len(np.unique(y_encoded)), activation='softmax')   # Capa de salida con activaciÃ³n softmax (convierte la salida en probabilidades de pertenencia a cada clase.)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n Entrenando modelo...\")\n",
        "history = model.fit(X_train, y_train, epochs=40, batch_size=8, validation_split=0.2, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "25ba8052",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " PrecisiÃ³n del modelo: 50.00%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\n",
            " Reporte de clasificaciÃ³n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       noise       1.00      1.00      1.00         2\n",
            "    sawtooth       0.00      0.00      0.00         2\n",
            "        sine       0.00      0.00      0.00         2\n",
            "      square       0.50      1.00      0.67         2\n",
            "    triangle       0.33      0.50      0.40         2\n",
            "\n",
            "    accuracy                           0.50        10\n",
            "   macro avg       0.37      0.50      0.41        10\n",
            "weighted avg       0.37      0.50      0.41        10\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dvcen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\dvcen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\dvcen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\n PrecisiÃ³n del modelo: {acc*100:.2f}%\")\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "print(\"\\n Reporte de clasificaciÃ³n:\")\n",
        "print(classification_report(y_test, y_pred, target_names=encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ” Probando con un sonido nuevo...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "ğŸ¯ El modelo predice que el timbre es: triangle\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nğŸ” Probando con un sonido nuevo...\")\n",
        "\n",
        "test_wave = generate_waveform(\"triangle\", 515, duration, sample_rate)\n",
        "test_signal = np.int16(test_wave / np.max(np.abs(test_wave)) * 32767)\n",
        "write(\"test_triangle.wav\", sample_rate, test_signal)\n",
        "\n",
        "audio, sr = librosa.load(\"test_triangle.wav\", sr=44100)\n",
        "mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "mfcc_mean = np.mean(mfcc, axis=1).reshape(1, -1)\n",
        "mfcc_mean = mfcc_mean / np.max(np.abs(mfcc_mean))\n",
        "\n",
        "pred = model.predict(mfcc_mean)\n",
        "pred_class = encoder.inverse_transform([np.argmax(pred)])\n",
        "print(f\"ğŸ¯ El modelo predice que el timbre es: {pred_class[0]}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
